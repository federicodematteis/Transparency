{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import tee\n",
    "from tkinter.ttk import LabelFrame\n",
    "import matplotlib.pyplot as plt\n",
    "import ROOT\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#libraries for data analysis\n",
    "from pprint import pprint\n",
    "from collections import namedtuple\n",
    "import datetime\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import chisquare\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.python.keras.backend import get_session\n",
    "\n",
    "\n",
    "#------\n",
    "\n",
    "#Libraries for machine learning\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten, LeakyReLU, Add, Concatenate, Dot\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.utils  import plot_model\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import regularizers\n",
    "import seaborn as sns\n",
    "\n",
    "data_folder = ('/home/federico/root/root-6.24.06-install')\n",
    "#data_folder = ('/gwpool/users/fdematteis')\n",
    "\n",
    "metadata = pd.read_csv(f\"{data_folder}/fill_metadata_2017_10min.csv\")\n",
    "\n",
    "#----------------------------------------------------------\n",
    "#transparency data for a selected iRing : the target function\n",
    "\n",
    "#23\n",
    "data24=np.load(f\"{data_folder}/iRing23new.npy\")\n",
    "data24_df = pd.DataFrame(data24)\n",
    "data24_df.head()\n",
    "mean24=[]\n",
    "#25\n",
    "data25=np.load(f\"{data_folder}/iRing25new.npy\")\n",
    "data25_df = pd.DataFrame(data25)\n",
    "data25_df.head()\n",
    "mean25=[]\n",
    "\n",
    "#compute mean transparnecy in iRings \n",
    "for i in range (0, len(data24_df.axes[1])):\n",
    "    #mean of colums' entries of data_df (for each \"position\" in the cristal)\n",
    "    mean24 = np.append(mean24, np.mean(data24_df[i]))\n",
    "\n",
    "for i in range (0, len(data25_df.axes[1])):\n",
    "    mean25 = np.append(mean25, np.mean(data25_df[i]))\n",
    "#iring23\n",
    "mean24=mean24[mean24 != -1]\n",
    "metadata = metadata.iloc[:len(mean24)][mean24 != -1]\n",
    "#iring25\n",
    "mean25=mean25[mean25 != -1]\n",
    "metadata1 = metadata.iloc[:len(mean25)][mean25 != -1]\n",
    "\n",
    "#selecting metadata for fill (locking metadata to in_fill=1)\n",
    "fill=metadata[\"fill_num\"].unique()\n",
    "fill = fill[fill != 0]\n",
    "\n",
    "fill1=metadata1[\"fill_num\"].unique()\n",
    "fill1 = fill1[fill1 != 0]\n",
    "\n",
    "nonsmooth = [5830, 5837, 5839, 5840, 5842, 5864, 5882, 5887, 5954, 5984, 6024, \n",
    "             6030, 6041,\n",
    "             6057, 6084, 6089, 6090, 6091, 6096, 6105, 6106, 6116,\n",
    "             6152, 6159, 6160, 6167, 6168,\n",
    "             6192, 6193, \n",
    "             6263, 6318,\n",
    "             #escludo i fill che userò per il train\n",
    "             6324, 6371, 6031, 6356, 6053, 5958, 6110, 6046\n",
    "             \n",
    "#--------second tranche\n",
    "             ]\n",
    "nonsmooth1 = [5830, 5837, 5839, 5840, 5842, 5864, 5882, 5883, 5887, 5954, 5980,\n",
    "              5984,  6030, 6041, 6057, 6084, 6096, 6105, 6106, 6116, 6119, 6152, 6159,\n",
    "              6160, 6167, 6168, 6170, 6171, 6192, 6261, 6262, 6263, 6279, 6300, 6318, 6348,\n",
    "              6349,\n",
    "              #escludo i fill che userò per il train\n",
    "              6324, 6371, 6031, 6356, 6053, 5958, 6110, 6046\n",
    "              ]\n",
    "             \n",
    "for iev in range (0, len(nonsmooth)) :\n",
    "    #print(nonsmooth[iev])\n",
    "    fill = fill[fill != nonsmooth[iev]]\n",
    "\n",
    "for iev in range (0, len(nonsmooth1)) :\n",
    "    #print(nonsmooth[iev])\n",
    "    fill1 = fill1[fill1 != nonsmooth1[iev]]\n",
    "#ora escludo i fill che ho deselezionato dai dati di train\n",
    "#i fill di validation sono gia stati esclusi\n",
    "metadata_fill = metadata[metadata.fill_num.isin(fill)]\n",
    "metadata_fill = metadata_fill[(metadata_fill.lumi_inst >= 0.0001*1e9) & (metadata_fill.lumi_inst <= 0.0004*1e9) & (metadata_fill.lumi_in_fill >= 0.1*1e9)]\n",
    "fill_num = metadata_fill.fill_num.unique()\n",
    "\n",
    "metadata_fill1 = metadata[metadata.fill_num.isin(fill1)]\n",
    "metadata_fill1 = metadata_fill1[(metadata_fill1.lumi_inst >= 0.0001*1e9) & (metadata_fill1.lumi_inst <= 0.0004*1e9) & (metadata_fill1.lumi_in_fill >= 0.1*1e9)]\n",
    "fill_num1 = metadata_fill1.fill_num.unique()\n",
    "#fatto!\n",
    "\n",
    "transp_fill = []\n",
    "transp_fill1 = []\n",
    "lumi_inst_0 = []\n",
    "lumi_int_0 = []\n",
    "#calcolo la main transparency per ognuno dei due iRing\n",
    "for k in fill_num:\n",
    "#transparency relativa ai fill selezionati\n",
    "    df = metadata_fill[metadata_fill.fill_num == k]\n",
    "    transp = [mean24[i] for i in df.index.values]\n",
    "    #transp ha la grandezza del dataframe ristretto al k esimo fill\n",
    "    transp = transp/transp[0]\n",
    "    transp_fill = np.append(transp_fill, transp)\n",
    "    a = np.empty(np.size(transp))\n",
    "    b = np.empty(np.size(transp))\n",
    "    a.fill(df['lumi_inst'].iloc[0])\n",
    "    b.fill(df['lumi_int'].iloc[0])\n",
    "    lumi_inst_0 = np.append(lumi_inst_0, a)\n",
    "    lumi_int_0 = np.append(lumi_int_0, b)\n",
    "    #in transp_fill ci sono i dati di trasparenza normalizzata per ogni fill;\n",
    "#-------\n",
    "for k in fill_num1:\n",
    "    df1 = metadata_fill1[metadata_fill1.fill_num == k]\n",
    "    transp1 = [mean25[i] for i in df1.index.values]\n",
    "    transp1 = transp1/transp1[0]\n",
    "    transp_fill1 = np.append(transp_fill1, transp1)\n",
    "\n",
    "#-----iring23 \n",
    "instLumi = (1e-9)*metadata_fill.loc[:,'lumi_inst']\n",
    "intLumiLHC = (1e-9)*metadata_fill.loc[:,'lumi_int']\n",
    "infillLumi = (1e-9)*metadata_fill.loc[:,'lumi_in_fill']\n",
    "lastfillLumi = (1e-9)*metadata_fill.loc[:,'lumi_last_fill']\n",
    "filltime = (1e-9)*metadata_fill.loc[:,'time_in_fill']\n",
    "lastpointLumi = (1e-9)*metadata_fill.loc[:, 'lumi_since_last_point']\n",
    "true_time = (1e-9)*metadata_fill.loc[:, 'time']\n",
    "\n",
    "ring_index = np.zeros(len(metadata_fill))\n",
    "for i in range (0, len(ring_index)):\n",
    "    ring_index[i] = 23\n",
    "    \n",
    "#-----iring25\n",
    "instLumi1 = (1e-9)*metadata_fill1.loc[:,'lumi_inst']\n",
    "intLumiLHC1 = (1e-9)*metadata_fill1.loc[:,'lumi_int']\n",
    "infillLumi1 = (1e-9)*metadata_fill1.loc[:,'lumi_in_fill']\n",
    "lastfillLumi1 = (1e-9)*metadata_fill1.loc[:,'lumi_last_fill']\n",
    "filltime1 = (1e-9)*metadata_fill1.loc[:,'time_in_fill']\n",
    "lastpointLumi1 = (1e-9)*metadata_fill1.loc[:, 'lumi_since_last_point']\n",
    "true_time1 = (1e-9)*metadata_fill1.loc[:, 'time']\n",
    "\n",
    "ring_index1 = np.zeros(len(metadata_fill1))\n",
    "for i in range (0, len(ring_index1)):\n",
    "    ring_index1[i] = 25\n",
    "\n",
    "#now i have to merge transparency datas and luminosity metadatas\n",
    "#metadata merge\n",
    "merged_instLumi = np.append(instLumi, instLumi1)\n",
    "merged_intLumiLHC = np.append(intLumiLHC, intLumiLHC1)   \n",
    "merged_infillLumi = np.append(infillLumi, infillLumi1)\n",
    "merged_lastfillLumi = np.append(lastfillLumi, lastfillLumi1)\n",
    "merged_filltime = np.append(filltime, filltime1)\n",
    "merged_ring_index = np.append(ring_index, ring_index1)\n",
    "#transparency merge \n",
    "\n",
    "transp_train = np.append(transp_fill, transp_fill1)\n",
    "all_inputs_train=np.stack((merged_instLumi, merged_infillLumi, merged_intLumiLHC, merged_filltime, merged_ring_index, merged_lastfillLumi), axis=-1)\n",
    "\n",
    "#Validation dataset\n",
    "#fill usati per il test\n",
    "#filltest = [6324, 6371, 6031, 6356, 6053, 5958, 6110, 6046]\n",
    "filltest = [5958, 6031, 6046, 6053, 6110, 6324, 6356, 6371]\n",
    "metadata_test = metadata[metadata.fill_num.isin(filltest)]\n",
    "\n",
    "metadata_test = metadata_test[(metadata_test.lumi_inst >= 0.0001*1e9) & (metadata_test.lumi_inst <= 0.0004*1e9) & (metadata_test.lumi_in_fill >= 0.1*1e9)]\n",
    "#estraggo transparency per il test\n",
    "transp_test = mean24[metadata_test.index.values[0]:metadata_test.index.values[0]+len(metadata_test.axes[0])]\n",
    "fill_num_test = metadata_test.fill_num.unique()\n",
    "\n",
    "#normalizzo i dati di trasparenza per il test\n",
    "#è sbagliato normalizzare così, devo normalizzare nello stesso modo usato per i metadati di train\n",
    "transp_test_final=[]\n",
    "\n",
    "for k in fill_num_test:\n",
    "    df_test = metadata_test[metadata_test.fill_num == k]\n",
    "    #sto scegliendo i dati di trasparenza dall'iRing 23 che quì è indicato con 24\n",
    "    transp_test = [mean24[i] for i in df_test.index.values]\n",
    "    transp_test = transp_test/transp_test[0]\n",
    "    transp_test_final = np.append(transp_test_final, transp_test)\n",
    "\n",
    "\n",
    "\n",
    "print(len(transp_test_final))\n",
    "#in metadata_test ci sono i metadati relativi ai fill che uso per il train\n",
    "\n",
    "#Ora devo preparare i metadati di validation usando metadata_test\n",
    "\n",
    "instLumi_test = (1e-9)*metadata_test.loc[:,'lumi_inst']\n",
    "intLumiLHC_test = (1e-9)*metadata_test.loc[:,'lumi_int']\n",
    "infillLumi_test = (1e-9)*metadata_test.loc[:,'lumi_in_fill']\n",
    "lastfillLumi_test = (1e-9)*metadata_test.loc[:,'lumi_last_fill']\n",
    "filltime_test = (1e-9)*metadata_test.loc[:,'time_in_fill']\n",
    "lastpointLumi_test = (1e-9)*metadata_test.loc[:, 'lumi_since_last_point']\n",
    "true_time_test = (1e-9)*metadata_test.loc[:, 'time']\n",
    "\n",
    "ring_index_test = np.zeros(len(metadata_test))\n",
    "for iev in range (0, len(metadata_test)):\n",
    "    ring_index_test[iev] = 23\n",
    "\n",
    "all_inputs_test=np.stack((instLumi_test, infillLumi_test, intLumiLHC_test, filltime_test, ring_index_test, lastfillLumi_test), axis=-1)\n",
    "\n",
    "# Machine learning  ─=≡Σ(([ ⊐•̀⌂•́]⊐\n",
    "\n",
    "#DNN structure\n",
    "inputs = Input(shape=(6,))\n",
    "hidden1 = Dense(256, activation='leaky_relu', kernel_regularizer=regularizers.l1_l2(l1=1e-9, l2=1e-10), bias_regularizer=regularizers.l2(1e-10), activity_regularizer=regularizers.l2(1e-10))(inputs)\n",
    "drop1=Dropout(0.2)(hidden1)\n",
    "hidden2 = Dense(128, activation='leaky_relu', kernel_regularizer=regularizers.l1_l2(l1=1e-9, l2=1e-10), bias_regularizer=regularizers.l2(1e-10), activity_regularizer=regularizers.l2(1e-10))(drop1)\n",
    "drop2=Dropout(0.2)(hidden2)\n",
    "hidden3 = Dense(64, activation='leaky_relu', kernel_regularizer=regularizers.l1_l2(l1=1e-9, l2=1e-10), bias_regularizer=regularizers.l2(1e-10), activity_regularizer=regularizers.l2(1e-10))(drop2)\n",
    "outputs = Dense(1) (hidden3)\n",
    "\n",
    "#model checkpoint and early stopping\n",
    "filepath = \"/home/federico/root/root-6.24.06-install/weights\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_mean_squared_error', verbose=0, save_best_only=True, mode='min')\n",
    "callback_list=[checkpoint]\n",
    "early_stopping = EarlyStopping(monitor='val_mean_squared_error', patience=100, verbose=0, restore_best_weights= True)\n",
    "\n",
    "model = Model ( inputs=inputs, outputs=outputs )\n",
    "model.compile(loss='MSE', optimizer='adam', metrics=['mean_squared_error'])\n",
    "\n",
    "#write the summary of the network\n",
    "model.summary()\n",
    "\n",
    "#plot the network\n",
    "plot_model(\n",
    "    model,\n",
    "    to_file=\"model.png\",\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    "    rankdir=\"TB\",\n",
    ")\n",
    "\n",
    "all_inputs_training   = all_inputs_train\n",
    "all_inputs_validation = all_inputs_test\n",
    "transp_training   = transp_train\n",
    "transp_validation = transp_test_final\n",
    "\n",
    "#print(all_inputs_validation)\n",
    "\n",
    "#now actually performing the train (ง •̀_•́)ง\n",
    "history = model.fit( all_inputs_training, transp_training, validation_data = (all_inputs_validation,transp_test_final), epochs=500, verbose=2, callbacks=[early_stopping])\n",
    "\n",
    "#plot the training loss\n",
    "plt.plot( history.history[\"loss\"], label = 'train' )\n",
    "plt.plot( history.history[\"val_loss\"], label = 'validation' )#devo inserire momenti senza radiazione per il train; non mi interessa usarli nel test\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# # plot MSE\n",
    "# plt.plot(history.history[\"mean_squared_error\"], label = 'train')\n",
    "# plt.plot(history.history[\"val_mean_squared_error\"], label='validation')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "#now test the performance of the DNN ಠ_ರೃ\n",
    "transp_predicted_validation = model.predict(all_inputs_validation)\n",
    "prediction_single_fill=[]\n",
    "#plot on abs time of metadata for a selected fill_num\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "from sklearn import linear_model\n",
    "\n",
    "# set up the LIME explainer\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(all_inputs_train,\n",
    "                                                  training_labels = None,\n",
    "                                                  feature_names = None,\n",
    "                                                  mode = 'regression',\n",
    "                                                  discretize_continuous = False)\n",
    "\n",
    "# you need to modify the output since keras outputs a tensor and LIME takes arrays\n",
    "def predict(x):\n",
    "    return model.predict(x).flatten()\n",
    "\n",
    "# compute the explainer. Chose Huber for its robustness against outliers\n",
    "i=1\n",
    "exp = explainer.explain_instance(all_inputs_train[i,:],\n",
    "                                 predict,\n",
    "                                 num_features=5,\n",
    "                                 distance_metric='euclidean',\n",
    "                                 num_samples=len(all_inputs_train),\n",
    "                                 model_regressor = linear_model.HuberRegressor())\n",
    "\n",
    "# generate plot for one item\n",
    "exp.show_in_notebook(show_table=True, predict_proba=True, show_predicted_value=True)\n",
    "#[exp.as_pyplot_figure(label=1)]\n",
    "#plt.figure()\n",
    "\n",
    "\n",
    "#SP LIME \n",
    "from lime import submodular_pick\n",
    "\n",
    "#set up sp lime with 20 samples. The more amount of samples time increases dramatically\n",
    "sp_obj = submodular_pick.SubmodularPick(explainer, \n",
    "                                        all_inputs_train,\n",
    "                                        predict, \n",
    "                                        sample_size=20,\n",
    "                                        num_features=5,\n",
    "                                        num_exps_desired=5)\n",
    "\n",
    "#get explanation matrix\n",
    "W_matrix = pd.DataFrame([dict(this.as_list()) for this in sp_obj.explanations])\n",
    "\n",
    "#get overall mean explanation for each feature\n",
    "matrix_mean = W_matrix.mean()\n",
    "plt.figure(figsize=(14,6))\n",
    "matrix_mean.sort_values(ascending=False).plot.bar()\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(metadata_test.time, transp_validation, \".b-\", markersize=3, linewidth=0.75, label=\"measured\")\n",
    "plt.plot(metadata_test.time, transp_predicted_validation, \".r-\", markersize=3, linewidth=0.75, label=\"predicted\")\n",
    "plt.xlabel(\"absolute time\")\n",
    "plt.ylabel(\"mean transparency\")\n",
    "plt.tick_params(labelsize=7)\n",
    "plt.title(f\"fill {fill_num_test}\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# m=0\n",
    "# for k in fill_num_test:\n",
    "#     df_test = metadata_test[metadata_test.fill_num == k]\n",
    "#     transp_test = [mean24[i] for i in df_test.index.values]\n",
    "#     transp_test = transp_test/transp_test[0]\n",
    "#     print('lunghezza del primo fill')\n",
    "#     print(len(transp_test))\n",
    "#     for j in range (0, len(transp_test)):\n",
    "#         prediction_single_fill[j] = transp_predicted_validation[m+j] \n",
    "\n",
    "#     m=m+j+1\n",
    "#         #alla fine del primo for m è lungo quanto il primo fill: len(transp_test)\n",
    "#         #nel secondo for m parte da len(transp_test)+1 e va fino alla lunghezza del secondo fill\n",
    "#         #sempre in questo for posso calcolare mse e salvarlo in un array\n",
    "#     #k=len(transp_test)+1\n",
    "#     plt.plot(metadata_test.time, transp_test, \".b-\", markersize=3, linewidth=0.75, label=\"measured\")\n",
    "#     plt.plot(metadata_test.time, prediction_single_fill, \".r-\", markersize=3, linewidth=0.75, label=\"predicted\")\n",
    "#     plt.xlabel(\"absolute time\")\n",
    "#     plt.ylabel(\"mean transparency\")\n",
    "#     plt.tick_params(labelsize=7)\n",
    "#     plt.title(f\"fill {fill_num_test}\")\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "#get mse value after the train\n",
    "error=0\n",
    "for i in range (0, len(transp_validation)):\n",
    "    error = error + (transp_validation[i]-transp_predicted_validation[i])*(transp_validation[i]-transp_predicted_validation[i])\n",
    "\n",
    "#mean square error: 1/N sum((O-P)^2)\n",
    "mse = error/len(transp_validation)\n",
    "print(f\"mean square error for fill {filltest}\")\n",
    "print(mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
